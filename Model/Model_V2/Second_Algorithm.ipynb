{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "with K.tf.device('/gpu:0'):\n",
    "    config = tf.ConfigProto(device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:(1/2) done. 320 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 50 sec\n",
      "WARNING:root:Finished parsing 900,000 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 38 sec\n",
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:(1/2) done. 54 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 8 sec\n",
      "WARNING:root:Finished parsing 900,000 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 10 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (900000, 70)\n",
      "Shape of decoder input: (900000, 11)\n",
      "Shape of decoder target: (900000, 11)\n",
      "Size of vocabulary for body_pp.dpkl: 8,002\n",
      "Size of vocabulary for title_pp.dpkl: 4,502\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "traindf, testdf = train_test_split(pd.read_csv('github_issues.csv').sample(n=1000000),\n",
    "                                   test_size=.10)\n",
    "\n",
    "train_body_raw = traindf.body.tolist()\n",
    "train_title_raw = traindf.issue_title.tolist()\n",
    "\n",
    "#traindf\n",
    "eng_rec = list()\n",
    "for i in range(len(traindf)):\n",
    "    temp_ord = ord(traindf.iloc[i,:].issue_title[0])\n",
    "    if((temp_ord >= ord('a') and temp_ord <= ord('z'))\n",
    "       or(temp_ord >= ord('A') and temp_ord <= ord('Z'))or(temp_ord >= ord('0') and temp_ord <= ord('9'))): \n",
    "        eng_rec.append(i)\n",
    "traindf = traindf.iloc[eng_rec]\n",
    "#testdf\n",
    "eng_rec = list()\n",
    "for i in range(len(testdf)):\n",
    "    temp_ord = ord(testdf.iloc[i,:].issue_title[0])\n",
    "    if((temp_ord >= ord('a') and temp_ord <= ord('z'))\n",
    "       or(temp_ord >= ord('A') and temp_ord <= ord('Z'))or(temp_ord >= ord('0') and temp_ord <= ord('9'))): \n",
    "        eng_rec.append(i)\n",
    "testdf = testdf.iloc[eng_rec]\n",
    "\n",
    "latent_dim = 300\n",
    "from ktext.preprocess import processor\n",
    "\n",
    "body_pp = processor(keep_n=8000, padding_maxlen=70)\n",
    "train_body_vecs = body_pp.fit_transform(train_body_raw)\n",
    "\n",
    "title_pp = processor(append_indicators=True, keep_n=4500,\n",
    "                     padding_maxlen=12, padding ='post')\n",
    "\n",
    "# process the title data\n",
    "train_title_vecs = title_pp.fit_transform(train_title_raw)\n",
    "\n",
    "import dill as dpickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('body_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(body_pp, f)\n",
    "\n",
    "with open('title_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(title_pp, f)\n",
    "\n",
    "# Save the processed data\n",
    "np.save('train_title_vecs.npy', train_title_vecs)\n",
    "np.save('train_body_vecs.npy', train_body_vecs)\n",
    "\n",
    "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor\n",
    "\n",
    "encoder_input_data, doc_length = load_encoder_inputs('train_body_vecs.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs('train_title_vecs.npy')\n",
    "sum_length = decoder_input_data.shape[1]\n",
    "\n",
    "num_encoder_tokens, body_pp = load_text_processor('body_pp.dpkl')\n",
    "num_decoder_tokens, title_pp = load_text_processor('title_pp.dpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization, SimpleRNN, RepeatVector, Flatten, TimeDistributed\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "def define_models(n_input, n_output, n_units):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(n_input,), name=\"Encoder-Input\")\n",
    "    x = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
    "    x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(x)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states, name='Encoder-Model')\n",
    "\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None,), name=\"Decoder-Input\")\n",
    "    dec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
    "    dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(dec_bn, initial_state=encoder_states)\n",
    "    x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_outputs)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax',name='Final-Output-Dense')\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(None,))\n",
    "    decoder_state_input_c = Input(shape=(None,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(dec_bn, initial_state=decoder_states_inputs)\n",
    "    x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_outputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder-Input (InputLayer)      (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Body-Word-Embedding (Embedding) (None, 70, 300)      2400600     Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Word-Embedding (Embeddi (None, None, 300)    1350600     Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Batchnorm-1 (BatchNorma (None, 70, 300)      1200        Body-Word-Embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-1 (BatchNorma (None, None, 300)    1200        Decoder-Word-Embedding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 300), (None, 721200      Encoder-Batchnorm-1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 300),  721200      Decoder-Batchnorm-1[0][0]        \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-2 (BatchNorma (None, None, 300)    1200        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Final-Output-Dense (Dense)      (None, None, 4502)   1355102     Decoder-Batchnorm-2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 6,552,302\n",
      "Trainable params: 6,550,502\n",
      "Non-trainable params: 1,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 641.50 483.00\" width=\"642pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 637.5,-479 637.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139718481844936 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139718481844936</title>\n",
       "<polygon fill=\"none\" points=\"59,-438.5 59,-474.5 264,-474.5 264,-438.5 59,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-451.9\">Encoder-Input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139718506812640 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139718506812640</title>\n",
       "<polygon fill=\"none\" points=\"27.5,-365.5 27.5,-401.5 295.5,-401.5 295.5,-365.5 27.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-378.9\">Body-Word-Embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 139718481844936&#45;&gt;139718506812640 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139718481844936-&gt;139718506812640</title>\n",
       "<path d=\"M161.5,-438.4551C161.5,-430.3828 161.5,-420.6764 161.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0001,-411.5903 161.5,-401.5904 158.0001,-411.5904 165.0001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139716161703832 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139716161703832</title>\n",
       "<polygon fill=\"none\" points=\"384.5,-365.5 384.5,-401.5 590.5,-401.5 590.5,-365.5 384.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-378.9\">Decoder-Input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139716166314416 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139716166314416</title>\n",
       "<polygon fill=\"none\" points=\"341.5,-292.5 341.5,-328.5 633.5,-328.5 633.5,-292.5 341.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-305.9\">Decoder-Word-Embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 139716161703832&#45;&gt;139716166314416 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139716161703832-&gt;139716166314416</title>\n",
       "<path d=\"M487.5,-365.4551C487.5,-357.3828 487.5,-347.6764 487.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"491.0001,-338.5903 487.5,-328.5904 484.0001,-338.5904 491.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139718025277224 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139718025277224</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 323,-328.5 323,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-305.9\">Encoder-Batchnorm-1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139718506812640&#45;&gt;139718025277224 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139718506812640-&gt;139718025277224</title>\n",
       "<path d=\"M161.5,-365.4551C161.5,-357.3828 161.5,-347.6764 161.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0001,-338.5903 161.5,-328.5904 158.0001,-338.5904 165.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139716166268856 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139716166268856</title>\n",
       "<polygon fill=\"none\" points=\"303.5,-219.5 303.5,-255.5 627.5,-255.5 627.5,-219.5 303.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"465.5\" y=\"-232.9\">Decoder-Batchnorm-1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139716166314416&#45;&gt;139716166268856 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139716166314416-&gt;139716166268856</title>\n",
       "<path d=\"M482.0618,-292.4551C479.6026,-284.2951 476.6402,-274.4652 473.9048,-265.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"477.1886,-264.1551 470.9519,-255.5904 470.4863,-266.175 477.1886,-264.1551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139718218493848 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139718218493848</title>\n",
       "<polygon fill=\"none\" points=\"148,-219.5 148,-255.5 263,-255.5 263,-219.5 148,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-232.9\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 139718025277224&#45;&gt;139718218493848 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139718025277224-&gt;139718218493848</title>\n",
       "<path d=\"M172.3764,-292.4551C177.5063,-283.9441 183.7312,-273.6165 189.3936,-264.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"192.4316,-265.9617 194.5962,-255.5904 186.4364,-262.3481 192.4316,-265.9617\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139716166427088 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139716166427088</title>\n",
       "<polygon fill=\"none\" points=\"267,-146.5 267,-182.5 382,-182.5 382,-146.5 267,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-159.9\">lstm_4: LSTM</text>\n",
       "</g>\n",
       "<!-- 139716166268856&#45;&gt;139716166427088 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139716166268856-&gt;139716166427088</title>\n",
       "<path d=\"M430.6461,-219.4551C411.8345,-209.7157 388.428,-197.5975 368.3852,-187.2207\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.9313,-184.0799 359.4417,-182.5904 366.7129,-190.2962 369.9313,-184.0799\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139718218493848&#45;&gt;139716166427088 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139718218493848-&gt;139716166427088</title>\n",
       "<path d=\"M234.9157,-219.4551C250.363,-209.979 269.4816,-198.2508 286.0845,-188.0658\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"288.3164,-190.8028 295.0102,-182.5904 284.6561,-184.836 288.3164,-190.8028\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139716170219248 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139716170219248</title>\n",
       "<polygon fill=\"none\" points=\"162.5,-73.5 162.5,-109.5 486.5,-109.5 486.5,-73.5 162.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-86.9\">Decoder-Batchnorm-2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139716166427088&#45;&gt;139716170219248 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>139716166427088-&gt;139716170219248</title>\n",
       "<path d=\"M324.5,-146.4551C324.5,-138.3828 324.5,-128.6764 324.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"328.0001,-119.5903 324.5,-109.5904 321.0001,-119.5904 328.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139716170426464 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>139716170426464</title>\n",
       "<polygon fill=\"none\" points=\"220.5,-.5 220.5,-36.5 428.5,-36.5 428.5,-.5 220.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-13.9\">Final-Output-Dense: Dense</text>\n",
       "</g>\n",
       "<!-- 139716170219248&#45;&gt;139716170426464 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>139716170219248-&gt;139716170426464</title>\n",
       "<path d=\"M324.5,-73.4551C324.5,-65.3828 324.5,-55.6764 324.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"328.0001,-46.5903 324.5,-36.5904 321.0001,-46.5904 328.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792000 samples, validate on 108000 samples\n",
      "Epoch 1/5\n",
      "792000/792000 [==============================] - 215s 272us/step - loss: 3.0047 - val_loss: 2.5769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shirley/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_4:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "792000/792000 [==============================] - 125s 158us/step - loss: 2.4459 - val_loss: 2.4591\n",
      "Epoch 3/5\n",
      "792000/792000 [==============================] - 125s 158us/step - loss: 2.3104 - val_loss: 2.4292\n",
      "Epoch 4/5\n",
      "792000/792000 [==============================] - 128s 162us/step - loss: 2.2289 - val_loss: 2.4224\n",
      "Epoch 5/5\n",
      "792000/792000 [==============================] - 153s 194us/step - loss: 2.1685 - val_loss: 2.4285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "script_name_base = 'tutorial_seq2seq'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "\n",
    "batch_size = 1200\n",
    "epochs = 5\n",
    "\n",
    "model, encoder_model, decoder_model = define_models(doc_length, 11, 300)\n",
    "\n",
    "model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "from seq2seq_utils import viz_model_architecture\n",
    "viz_model_architecture(model)\n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])\n",
    "\n",
    "#save model\n",
    "model.save('model_tutorial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example # 48374\n",
      "Issue Body:\n",
      " _i have:_ - x searched existing issues http://github.com/darkstarproject/darkstar/issues/ to see if the issue i am posting has already been addressed or opened by another contributor - x checked the commit log to see if my issue has been resolved since my server was last updated _client version_ type /ver in game : 30170905_05 _server version_ type !revision in game : unknown _source branch_ master/stable : master _additional information_ steps to reproduce/expected behavior : i think this https://github.com/darkstarproject/darkstar/blob/master/scripts/globals/abilities/pets/somnolence.lua is basically missing a: target:delhp dmg ; target:updateenmityfromdamage pet,dmg ; one thing i couldn't figure out though is why it says target takes 0 points of damage when i use it. i'm assuming the returned value is for the message? other than that it won't be doing any damage at all. \n",
      "\n",
      "Original Title: somnolence has damage calculation but doesn't subtract it from target\n",
      "\n",
      "****** Machine Generated Title (Prediction) ******: the number of the number number number number number number number number\n",
      "\n",
      "Example # 9120\n",
      "Issue Body:\n",
      " imagine having a use maximum collateral option right below the collateral ratio slider which would use as collateral all available bts currently in the active account. i am always doing this manually. if i am going to sleep i always want to have the maximum collateral just in case some drastic crash happens. this would help reduce margin calls because it would lower the margin call price for users who don't know they can enter more collateral than the 5% precision slider allows. the only issue i see with this is having some bts left over for fees. maybe the maximum could actually be slightly less than the maximum, leaving only enough bts to match the current price for collateral adjustment so that the user can unlock their bts at a later date. we can't have the user stuck with locked up collateral and no fees to unlock it. \n",
      "\n",
      "Original Title: add max collateral feature\n",
      "\n",
      "****** Machine Generated Title (Prediction) ******: feature request add a option to the use the number of the\n",
      "\n",
      "Example # 75054\n",
      "Issue Body:\n",
      " docs: https://developer.chrome.com/extensions/optionsv2 > in a future version of chrome, ..., they will always be embedded in chrome://extensions - so migrate as soon as possible. with a ui similar to this: ! https://developer.chrome.com/static/images/options-ui.png plan: 1. sit back and relax. there's a lot of time. date's to be declared. 2. in the embedded page, we'll just notify bg.js to execute js https://developer.chrome.com/extensions/runtime method-openoptionspage to open the default options page. hardly any trouble at all. \n",
      "\n",
      "Original Title: we need to upgrade our options page asap\n",
      "\n",
      "****** Machine Generated Title (Prediction) ******: add support for the number number number number number number number number\n",
      "\n",
      "Example # 64422\n",
      "Issue Body:\n",
      " linux ubuntu 16.04 lts after running the pharolauncher and launching a few images with it, if i close the pharolauncher image, all the other images are killed without save prompts. and if the quit on launch setting is on, whenever pharolauncher launches an image, it quits itself, which closes the image just launched. since quit on launch is on by default, pharolauncher looks like it doesn't work by default. \n",
      "\n",
      "Original Title: closing the pharolauncher image closes all the images it launched\n",
      "\n",
      "****** Machine Generated Title (Prediction) ******: number number number number number number number number number number number number\n",
      "\n",
      "Example # 52378\n",
      "Issue Body:\n",
      " in org.a.a.a.f number of crashes: 1 impacted devices: 1 there's a lot more information about this crash on crashlytics.com: https://fabric.io/momo6/android/apps/com.immomo.momo/issues/59900208be077a4dcc04a2b6?utm_medium=service_hooks-github&utm_source=issue_impact https://fabric.io/momo6/android/apps/com.immomo.momo/issues/59900208be077a4dcc04a2b6?utm_medium=service_hooks-github&utm_source=issue_impact \n",
      "\n",
      "Original Title: abstractdao.java line 461\n",
      "\n",
      "****** Machine Generated Title (Prediction) ******: line number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Seq2Seq_Inference(object):\n",
    "    def __init__(self,\n",
    "                 encoder_preprocessor,\n",
    "                 decoder_preprocessor,):\n",
    "\n",
    "        self.pp_body = encoder_preprocessor\n",
    "        self.pp_title = decoder_preprocessor\n",
    "        self.seq2seq_model, self.encoder_model, self.decoder_model = model, encoder_model, decoder_model\n",
    "        self.default_max_len_title = self.pp_title.padding_maxlen\n",
    "        self.nn = None\n",
    "        self.rec_df = None\n",
    "    def generate_issue_title(self,\n",
    "                             raw_input_text,\n",
    "                             max_len_title=None):\n",
    "        if max_len_title is None:\n",
    "            max_len_title = self.default_max_len_title\n",
    "        raw_tokenized = self.pp_body.transform([raw_input_text])\n",
    "        body_encoding = self.encoder_model.predict(raw_tokenized)\n",
    "        original_body_encoding = body_encoding\n",
    "        state_value = np.array(self.pp_title.token2id['_start_']).reshape(1, 1)\n",
    "        decoded_sentence = []\n",
    "        stop_condition = False\n",
    "        while not stop_condition:\n",
    "            preds, st_h, st_c = self.decoder_model.predict([state_value] + body_encoding)\n",
    "            pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
    "            pred_word_str = self.pp_title.id2token[pred_idx]\n",
    "\n",
    "            if pred_word_str == '_end_' or len(decoded_sentence) >= max_len_title:\n",
    "                stop_condition = True\n",
    "                break\n",
    "            decoded_sentence.append(pred_word_str)\n",
    "            body_encoding = [st_h, st_c]\n",
    "            state_value = np.array(pred_idx).reshape(1, 1)\n",
    "\n",
    "        return original_body_encoding, ' '.join(decoded_sentence)\n",
    "\n",
    "    def print_example(self,\n",
    "                      i,\n",
    "                      body_text,\n",
    "                      title_text,):\n",
    "        if i:\n",
    "            print(f'Example # {i}')\n",
    "        print(f\"Issue Body:\\n {body_text} \\n\")\n",
    "        if title_text:\n",
    "            print(f\"Original Title: {title_text}\")\n",
    "        emb, gen_title = self.generate_issue_title(body_text)\n",
    "        print(f\"\\n****** Machine Generated Title (Prediction) ******: {gen_title}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    def demo_model_predictions(self,\n",
    "                               n,\n",
    "                               issue_df,\n",
    "                               threshold=1):\n",
    "        body_text = issue_df.body.tolist()\n",
    "        title_text = issue_df.issue_title.tolist()\n",
    "        url = issue_df.issue_url.tolist()\n",
    "\n",
    "        demo_list = np.random.randint(low=1, high=len(body_text), size=n)\n",
    "        for i in demo_list:\n",
    "            self.print_example(i,\n",
    "                               body_text=body_text[i],\n",
    "                               title_text=title_text[i],)\n",
    "\n",
    "\n",
    "\n",
    "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n",
    "                                 decoder_preprocessor=title_pp)\n",
    "\n",
    "seq2seq_inf.demo_model_predictions(n=5, issue_df=testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "ROUGE-l-f: 0.15205724508016866\n",
      "ROUGE-l-f: 129.41565725026797\n",
      "ROUGE-l-f: 247.62439126921305\n",
      "ROUGE-l-f: 381.18679074955537\n",
      "ROUGE-l-f: 519.5097222781053\n",
      "ROUGE-l-f: 651.8398995231631\n",
      "ROUGE-l-f: 779.4153141548747\n",
      "ROUGE-l-f: 904.9867820929622\n",
      "ROUGE-l-f: 1030.2055907869849\n",
      "ROUGE-l-f: 1158.915786729178\n",
      "ROUGE-l-f: 1281.3565026101828\n",
      "ROUGE-l-f: 1419.68698149768\n",
      "ROUGE-l-f: 1547.1102205676752\n",
      "ROUGE-l-f: 1681.0588629659687\n",
      "ROUGE-l-f: 1814.7430368366824\n",
      "ROUGE-l-f: 1945.1834757225836\n",
      "ROUGE-l-f: 2079.346562787094\n",
      "ROUGE-l-f: 2209.4451588045754\n",
      "ROUGE-l-f: 2338.1878466316525\n",
      "ROUGE-l-f: 2466.5080999739744\n",
      "ROUGE-l-f: 2601.7389744464026\n",
      "ROUGE-l-f: 2733.3649492201316\n",
      "ROUGE-l-f: 2862.9368392418837\n",
      "ROUGE-l-f: 2993.269973987495\n",
      "ROUGE-l-f: 3130.5458376701245\n",
      "ROUGE-l-f: 3252.881327731144\n",
      "ROUGE-l-f: 3378.617202705407\n",
      "ROUGE-l-f: 3506.7288570834316\n",
      "ROUGE-l-f: 3640.633112648838\n",
      "ROUGE-l-f: 3776.634810857354\n",
      "ROUGE-l-f: 3907.425536494421\n",
      "ROUGE-l-f: 4040.6683092281305\n",
      "ROUGE-l-f: 4176.8858900458345\n",
      "ROUGE-l-f: 4305.754182964997\n",
      "ROUGE-l-f: 4435.089998142058\n",
      "ROUGE-l-f: 4557.102816187774\n",
      "ROUGE-l-f: 4680.773081019789\n",
      "ROUGE-l-f: 4810.214016106882\n",
      "ROUGE-l-f: 4931.259419901143\n",
      "ROUGE-l-f: 5059.211291274221\n",
      "ROUGE-l-f: 5191.638868742205\n",
      "ROUGE-l-f: 5327.918517958226\n",
      "ROUGE-l-f: 5451.760614057315\n",
      "ROUGE-l-f: 5582.973077158839\n",
      "ROUGE-l-f: 5712.868156520776\n",
      "ROUGE-l-f: 5831.0597116850995\n",
      "ROUGE-l-f: 5953.235651065385\n",
      "ROUGE-l-f: 6075.256751648152\n",
      "ROUGE-l-f: 6205.438643659905\n",
      "ROUGE-l-f: 6327.155739995367\n",
      "ROUGE-l-f: 6455.733313478151\n",
      "ROUGE-l-f: 6588.014595156009\n",
      "ROUGE-l-f: 6703.241658418905\n",
      "ROUGE-l-f: 6832.794093886697\n",
      "ROUGE-l-f: 6968.2065469935405\n",
      "ROUGE-l-f: 7089.475756111712\n",
      "ROUGE-l-f: 7212.549233462618\n",
      "ROUGE-l-f: 7343.633051221517\n",
      "ROUGE-l-f: 7470.297934016219\n",
      "ROUGE-l-f: 7597.311449455427\n",
      "ROUGE-l-f: 7716.679481367527\n",
      "ROUGE-l-f: 7853.467244103466\n",
      "ROUGE-l-f: 7984.021638308074\n",
      "ROUGE-l-f: 8114.900544078251\n",
      "ROUGE-l-f: 8235.613422536777\n",
      "ROUGE-l-f: 8354.677358931718\n",
      "ROUGE-l-f: 8492.327542895808\n",
      "ROUGE-l-f: 8618.758767642452\n",
      "ROUGE-l-f: 8753.503106758591\n",
      "ROUGE-l-f: 8885.929676643522\n",
      "ROUGE-l-f: 9014.690620682637\n",
      "ROUGE-l-f: 9142.723796850616\n",
      "ROUGE-l-f: 9260.586674734042\n",
      "ROUGE-l-f: 9390.779646894001\n",
      "ROUGE-l-f: 9519.458952309596\n",
      "ROUGE-l-f: 9643.252014708743\n",
      "ROUGE-l-f: 9767.669707824949\n",
      "ROUGE-l-f: 9895.786278526506\n",
      "ROUGE-l-f: 10021.32965674927\n",
      "ROUGE-l-f: 10150.88891905156\n",
      "ROUGE-l-f: 10280.561493495887\n",
      "ROUGE-l-f: 10405.19265980636\n",
      "ROUGE-l-f: 10546.310206199467\n",
      "ROUGE-l-f: 10684.258164320532\n",
      "ROUGE-l-f: 10809.067555075051\n",
      "ROUGE-l-f: 10932.003008658981\n",
      "ROUGE-l-f: 11052.059434528328\n",
      "ROUGE-l-f: 11183.849709228993\n",
      "ROUGE-l-f: 11320.23435791463\n",
      "ROUGE-l-f: 11461.055917347652\n",
      "ROUGE-l-f: 11585.404413358674\n",
      "ROUGE-l-f: 11712.174243191896\n",
      "ROUGE-l-f: 11848.222011848635\n",
      "ROUGE-l-f: 11968.429339594008\n",
      "ROUGE-l-f: 12099.824940578235\n",
      "ROUGE-l-f: 12222.358096655462\n",
      "ROUGE-l-f: 12340.884340784169\n",
      "ROUGE-l-f: 12472.639416067886\n",
      "ROUGE-l-f: 12600.558454503993\n",
      "ROUGE-1: 0.14345152267824204\n",
      "ROUGE-2: 0.04741579328682749\n",
      "ROUGE-l: 0.1285785594341877\n",
      "Average of ROUGE-1, ROUGE-2 and ROUGE-l:  0.10648195846641907\n"
     ]
    }
   ],
   "source": [
    "# Import the ROUGE Package\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "test_title_text = testdf.issue_title.tolist()\n",
    "test_body_text = testdf.body.tolist()\n",
    "predict_title_text = [None]*len(test_body_text)\n",
    "rouge_1_f, rouge_2_f, rouge_l_f = 0, 0, 0\n",
    "\n",
    "length = len(test_body_text)\n",
    "\n",
    "# Generate the title for each issue body\n",
    "for i in range(length):\n",
    "    exm, predict_title_text[i] = seq2seq_inf.generate_issue_title(raw_input_text=test_body_text[i])\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "def calculate_rouge():\n",
    "    rouge_1_f, rouge_2_f, rouge_l_f = 0, 0, 0\n",
    "    for i in range(length):\n",
    "        # The rouge package does not accept empty strings \n",
    "        if predict_title_text[i]==\"\":\n",
    "            predict_title_text[i] = \"issue\"\n",
    "            \n",
    "        scores = rouge.get_scores(predict_title_text[i], test_title_text[i])\n",
    "        rouge_1_f = rouge_1_f + scores[0]['rouge-1']['f']\n",
    "        rouge_2_f = rouge_2_f + scores[0]['rouge-2']['f']\n",
    "        rouge_l_f = rouge_l_f + scores[0]['rouge-l']['f']\n",
    "        if i%1000==0:\n",
    "            print(\"ROUGE-l-f:\", rouge_l_f)\n",
    "    print(\"ROUGE-1:\", rouge_1_f / len(test_body_text))\n",
    "    print(\"ROUGE-2:\", rouge_2_f / len(test_body_text))\n",
    "    print(\"ROUGE-l:\", rouge_l_f / len(test_body_text))\n",
    "    print(\"Average of ROUGE-1, ROUGE-2 and ROUGE-l: \", (rouge_1_f + rouge_2_f + rouge_l_f) / 3 / len(test_body_text))\n",
    "\n",
    "calculate_rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
